{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\labkhand\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from data_utils import get_files\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import gc\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"./final_pickle\"\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images in testnew_sanaz : 400\n"
     ]
    }
   ],
   "source": [
    "path = \"real_dataset\"\n",
    "train_files, labels = get_files(path)\n",
    "nrof_images = len(labels)\n",
    "print(\"number of images in {} : {}\".format(path, nrof_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(model, preprocess_input, target_size, name):\n",
    "    ####### GENERATING FEATURES\n",
    "    path = os.path.join(out_dir, name)\n",
    "    if os.path.exists(path):\n",
    "        print(name, \" was already calculated!\")\n",
    "        return\n",
    "    start = time.time()\n",
    "    train_featues = []\n",
    "    for file in  tqdm(train_files):\n",
    "        img = image.load_img(file, target_size= target_size) \n",
    "        x = image.img_to_array(img) \n",
    "        x = np.expand_dims(x, axis=0) \n",
    "        x = preprocess_input(x) \n",
    "        features = model.predict(x) \n",
    "        features_reduce = features.squeeze() \n",
    "        train_featues.append(features_reduce)\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    with open (path, \"wb\") as f:\n",
    "        pickle.dump(train_featues, f)\n",
    "    print(name)\n",
    "    print('time spend: ' , (end - start)/60 , ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # ResNet50 - with fc\n",
    "    \n",
    "    from keras.applications.resnet50 import preprocess_input\n",
    "    from keras.applications import ResNet50\n",
    "    name = \"resnet50_before_softmax_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    model = Model(model.inputs, model.layers[-2].output)\n",
    "    yield (model, preprocess_input, target_size, name )    \n",
    "    \n",
    "    # VGG 16\n",
    "    from keras.applications.vgg16 import preprocess_input\n",
    "    from keras.applications import VGG16\n",
    "    name = \"vgg16_notop_maxpool_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = VGG16(weights='imagenet',include_top=False, pooling=max)\n",
    "    yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    # ResNet50\n",
    "    from keras.applications.resnet50 import preprocess_input\n",
    "    from keras.applications import ResNet50\n",
    "    name = \"resnet50_notop_maxpool_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = ResNet50(weights='imagenet',include_top=False, pooling=max)\n",
    "    yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    \n",
    "    from keras.applications.vgg16 import preprocess_input\n",
    "    from keras.applications import VGG16\n",
    "    name = \"vgg16_before_softmax_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = VGG16(weights='imagenet')\n",
    "    model = Model(model.inputs, model.layers[-2].output)\n",
    "    yield (model, preprocess_input, target_size, name ) \n",
    "    \n",
    "    \n",
    "    from keras.applications.inception_v3 import preprocess_input\n",
    "    from keras.applications import InceptionV3\n",
    "    name = \"inceptionv3_notop_maxpool_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = ResNet50(weights='imagenet',include_top=False, pooling=max)\n",
    "    yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    \n",
    "    from keras.applications.inception_v3 import preprocess_input\n",
    "    from keras.applications import InceptionV3\n",
    "    name = \"inceptionv3_before_softmax_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = VGG16(weights='imagenet')\n",
    "    model = Model(model.inputs, model.layers[-2].output)\n",
    "    yield (model, preprocess_input, target_size, name ) \n",
    "    \n",
    "    \n",
    "    from keras.applications.mobilenet import preprocess_input\n",
    "    from keras.applications import MobileNet\n",
    "    name = \"mobilenet_before_softmax_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = MobileNet(weights='imagenet')\n",
    "    model = Model(model.inputs, model.layers[-2].output)\n",
    "    yield (model, preprocess_input, target_size, name ) \n",
    "    \n",
    "    \n",
    "    from keras.applications.mobilenet import preprocess_input\n",
    "    from keras.applications import MobileNet\n",
    "    name = \"mobilenet_notop_maxpool_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = ResNet50(weights='imagenet',include_top=False, pooling=max)\n",
    "    yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    \n",
    "    from keras.applications.mobilenetv2 import preprocess_input\n",
    "    from keras.applications import MobileNetV2\n",
    "    name = \"mobilenet_v2_before_softmax_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = MobileNet(weights='imagenet')\n",
    "    model = Model(model.inputs, model.layers[-2].output)\n",
    "    yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    \n",
    "    from keras.applications.mobilenetv2 import preprocess_input\n",
    "    from keras.applications import MobileNetV2\n",
    "    name = \"mobilenet_v2_notop_maxpool_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = ResNet50(weights='imagenet',include_top=False, pooling=max)\n",
    "    yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    \n",
    "    from keras.applications.xception import preprocess_input\n",
    "    from keras.applications import Xception\n",
    "    name = \"xception_before_softmax_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = MobileNet(weights='imagenet')\n",
    "    model = Model(model.inputs, model.layers[-2].output)\n",
    "    yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    \n",
    "    from keras.applications.xception import preprocess_input\n",
    "    from keras.applications import Xception\n",
    "    name = \"xception_notop_maxpool_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = ResNet50(weights='imagenet',include_top=False, pooling=max)\n",
    "    yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    \n",
    "        \n",
    "    from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "    from keras.applications import InceptionResNetV2\n",
    "    name = \"inception_resnet_v2_before_softmax_final\"\n",
    "    target_size = (299, 299)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = InceptionResNetV2(weights='imagenet')\n",
    "    model = Model(model.inputs, model.layers[-2].output)\n",
    "    yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    \n",
    "    from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "    from keras.applications import InceptionResNetV2\n",
    "    name = \"inception_resnet_v2_notop_maxpool_final\"\n",
    "    target_size = (299, 299)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = InceptionResNetV2(weights='imagenet',include_top=False, pooling=max)\n",
    "    yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # DenseNet121 - with fc\n",
    "    from keras.applications.densenet import DenseNet121, preprocess_input\n",
    "    name = \"DenseNet121_before_softmax_ttt\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = DenseNet121(weights='imagenet')\n",
    "    model = Model(model.inputs, model.layers[-2].output)\n",
    "    yield (model, preprocess_input, target_size, name)    \n",
    "    \n",
    "     \n",
    "    # DenseNet121\n",
    "    from keras.applications.densenet import DenseNet121, preprocess_input\n",
    "    name = \"DenseNet121_notop_maxpool_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = DenseNet121(weights='imagenet',include_top=False, pooling=max)\n",
    "    yield (model, preprocess_input, target_size, name )     \n",
    "    \n",
    "    \n",
    "    # NASNetLarge - with fc\n",
    "    from keras.applications.nasnet import NASNetLarge, preprocess_input\n",
    "    name = \"NASNetLarge_before_softmax_final\"\n",
    "    target_size = (331, 331)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = NASNetLarge(weights='imagenet')\n",
    "    model = Model(model.inputs, model.layers[-2].output)\n",
    "    yield (model, preprocess_input, target_size, name)    \n",
    "\n",
    "     \n",
    "    # NASNetLarge\n",
    "    from keras.applications.nasnet import NASNetLarge, preprocess_input\n",
    "    name = \"NASNetLarge_notop_maxpool_final\"\n",
    "    target_size = (331, 331)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = NASNetLarge(weights='imagenet',include_top=False, pooling=max)\n",
    "    yield (model, preprocess_input, target_size, name )     \n",
    "    \n",
    "        \n",
    "    # NASNetMobile - with fc\n",
    "    from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
    "    name = \"NASNetMobile_before_softmax_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = NASNetMobile(weights='imagenet')\n",
    "    model = Model(model.inputs, model.layers[-2].output)\n",
    "    yield (model, preprocess_input, target_size, name)    \n",
    "    \n",
    "     \n",
    "    # NASNetLarge\n",
    "    from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
    "    name = \"NASNetMobile_notop_maxpool_final\"\n",
    "    target_size = (224, 224)\n",
    "    preprocess_input = preprocess_input\n",
    "    model = NASNetMobile(weights='imagenet',include_top=False, pooling=max)\n",
    "    yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    \n",
    "\n",
    "    # ResNeXt50 - with fc\n",
    "#     from keras.applications.resnext import ResNeXt50, preprocess_input\n",
    "#     name = \"ResNeXt50_before_softmax\"\n",
    "#     target_size = (224, 224)\n",
    "#     preprocess_input = preprocess_input\n",
    "#     model = ResNeXt50(weights='imagenet')\n",
    "#     model = Model(model.inputs, model.layers[-2].output)\n",
    "#     yield (model, preprocess_input, target_size, name)    \n",
    "    \n",
    "     \n",
    "#     # ResNeXt50\n",
    "#     from keras.applications.resnext import ResNeXt50, preprocess_input\n",
    "#     name = \"ResNeXt50_notop_maxpool\"\n",
    "#     target_size = (224, 224)\n",
    "#     preprocess_input = preprocess_input\n",
    "#     model = ResNeXt50(weights='imagenet',include_top=False, pooling=max)\n",
    "#     yield (model, preprocess_input, target_size, name )\n",
    "    \n",
    "    \n",
    "#     # ResNeXt101 - with fc\n",
    "#     from keras.applications.resnext import ResNeXt101, preprocess_input\n",
    "#     name = \"ResNeXt101_before_softmax\"\n",
    "#     target_size = (224, 224)\n",
    "#     preprocess_input = preprocess_input\n",
    "#     model = ResNeXt101(weights='imagenet')\n",
    "#     model = Model(model.inputs, model.layers[-2].output)\n",
    "#     yield (model, preprocess_input, target_size, name)    \n",
    "    \n",
    "     \n",
    "#     # ResNeXt101\n",
    "#     from keras.applications.resnext import ResNeXt101, preprocess_input\n",
    "\n",
    "#     name = \"ResNeXt101_notop_maxpool\"\n",
    "#     target_size = (224, 224)\n",
    "#     preprocess_input = preprocess_input\n",
    "#     model = ResNeXt101(weights='imagenet',include_top=False, pooling=max)\n",
    "#     yield (model, preprocess_input, target_size, name )\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(out_dir, \"labels_final\")\n",
    "if not os.path.exists(path):\n",
    "    with open (path, \"wb\") as f:\n",
    "        pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [09:45<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_before_softmax_ttt\n",
      "time spend:  9.75567813316981  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [04:57<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16_notop_maxpool_ttt\n",
      "time spend:  4.960683699448904  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\labkhand\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "100%|██████████| 400/400 [09:39<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_notop_maxpool_ttt\n",
      "time spend:  9.659094754854838  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [05:46<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16_before_softmax_ttt\n",
      "time spend:  5.774369692802429  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:21<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inceptionv3_notop_maxpool_ttt\n",
      "time spend:  10.362585484981537  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [05:37<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inceptionv3_before_softmax_ttt\n",
      "time spend:  5.631102768580119  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [04:31<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_before_softmax_ttt\n",
      "time spend:  4.527295506000518  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [09:36<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_notop_maxpool_ttt\n",
      "time spend:  9.607576978206634  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [04:31<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v2_before_softmax_ttt\n",
      "time spend:  4.525610752900442  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [1:36:32<00:00,  1.44s/it]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v2_notop_maxpool_ttt\n",
      "time spend:  96.54344194332758  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [04:32<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception_before_softmax_ttt\n",
      "time spend:  4.544123085339864  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [09:37<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception_notop_maxpool_ttt\n",
      "time spend:  9.631226110458375  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [2:20:20<00:00,  2.35s/it]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception_resnet_v2_before_softmax_ttt\n",
      "time spend:  140.34799090623855  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [15:49<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception_resnet_v2_notop_maxpool_ttt\n",
      "time spend:  15.829073333740235  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [13:51<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet121_before_softmax_ttt\n",
      "time spend:  13.854834798971812  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [13:55<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet121_notop_maxpool_ttt\n",
      "time spend:  13.91806042989095  minutes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 532 layers into a model with 526 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9e9eb6801d7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msave_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-457497b5567c>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m331\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m331\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[0mpreprocess_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNASNetLarge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_applications\\nasnet.py\u001b[0m in \u001b[0;36mNASNetLarge\u001b[1;34m(input_shape, include_top, weights, input_tensor, pooling, classes)\u001b[0m\n\u001b[0;32m    363\u001b[0m                   \u001b[0mpooling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpooling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m                   \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m                   default_size=331)\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_applications\\nasnet.py\u001b[0m in \u001b[0;36mNASNet\u001b[1;34m(input_shape, penultimate_filters, num_blocks, stem_block_filters, skip_reduction, filter_multiplier, include_top, weights, input_tensor, pooling, classes, default_size)\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                     file_hash='d81d89dc07e6e56530c4e77faddd61b5')\n\u001b[1;32m--> 289\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1159\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[1;32m-> 1161\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m    898\u001b[0m                          \u001b[1;34m'containing '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m                          \u001b[1;34m' layers into a model with '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 900\u001b[1;33m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[1;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 532 layers into a model with 526 layers."
     ]
    }
   ],
   "source": [
    "for model, preprocess_input, target_size, name in get_model():\n",
    "    try:\n",
    "        save_features(model, preprocess_input, target_size, name)\n",
    "        del model\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "    except Exception as e:\n",
    "        print(\"Error in \", name)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
